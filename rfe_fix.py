# -*- coding: utf-8 -*-
"""RFE FIX.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RlqlHjBkGlh7rhvinQnAVbJmKm9bMIZJ
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from sklearn.preprocessing import StandardScaler, OrdinalEncoder, LabelEncoder
from sklearn.linear_model import LogisticRegression, SGDClassifier
from sklearn.model_selection import StratifiedKFold, train_test_split, cross_validate
from sklearn.feature_selection import RFECV
# from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
# from sklearn.neighbors import KNeighborsClassifier
# from sklearn.tree import DecisionTreeClassifier
# from sklearn.ensemble import AdaBoostClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, plot_confusion_matrix
import warnings
warnings.filterwarnings("ignore")
# %matplotlib inline
random_state = 123

import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

path = "drive/MyDrive/Tugas Akhir/Coba/"
save_dir = "model-fs-25/"

df = pd.read_csv("drive/MyDrive/Tugas Akhir/dataset_B_05_2020.csv")
df.head()

# import pandas as pd
# path = "drive/MyDrive/Colab Notebook/Tugas Akhir/New/"
# save_dir = "model-1/"
# df = pd.read_csv("drive/MyDrive/dataset_B_05_2020.csv", index_col="url")
# df.head()

# #Encoding 'status' as label 1 & 0 , naming the field as target
# df['target'] = pd.get_dummies(df['status'])['legitimate'].astype('int')
# df.drop('status',axis = 1, inplace=True)
# df[['url','target']].head(5)

# tmp = df.isnull().sum().reset_index(name='missing_val')
# tmp[tmp['missing_val']!= 0]

# likely_cat = {}
# for var in df.iloc[:,1:].columns:
#     likely_cat[var] = 1.*df[var].nunique()/df[var].count() < 0.002 

# num_cols = []
# cat_cols = []
# for col in likely_cat.keys():
#     if (likely_cat[col] == False):
#         num_cols.append(col)
#     else:
#         cat_cols.append(col)

# df_distr =df.groupby('status')[num_cols].mean().reset_index().T
# df_distr.rename(columns={0:'0_Label',1:"1_Label"}, inplace=True)

# #plt.style.use('ggplot')
# plt.rcParams['axes.facecolor']='w'
# ax = df_distr[1:-3][['0_Label','1_Label']].plot(kind='bar', title ="Distribution of Average values across Target", figsize=(12, 8), legend=True, fontsize=12)
# ax.set_xlabel("Numerical Features", fontsize=14)
# ax.set_ylabel("Average Values", fontsize=14)
# plt.show()

df.dtypes
df.isnull().sum()
df = df.dropna()
df.isnull().sum()

"""Analisis Data Eksplorasi

Buat histogram untuk setiap fitur numerik terhadap status
"""

# Make histogram for every numeric features against status.
for column in df.select_dtypes("number").columns:
    df.pivot(columns="status")[column].plot.hist(alpha=0.5)
    plt.title(column)
    plt.show()

# # # Then, make bar plot for every categorical features against status.
# import matplotlib .pyplot as plt
# for column in df.select_dtypes("object").columns.drop("status"):
#     df.pivot(columns="status")[column].apply(pd.value_counts).plot.bar(stacked=True)
#     plt.title(column)
#     plt.show()

"""Feature Engineering and Selection"""

X = df.drop(columns=["status"])
y = df["status"]

scaler = StandardScaler()
X[X.select_dtypes("number").columns] = scaler.fit_transform(X.select_dtypes("number"))

ordEnc = OrdinalEncoder(dtype=np.int)
X[X.select_dtypes("object").columns] = ordEnc.fit_transform(X.select_dtypes("object"))
labEnc = LabelEncoder()
y = labEnc.fit_transform(y)

"""LogisticRegression"""

estimator = LogisticRegression(random_state=random_state)
rfecv = RFECV(estimator=estimator, cv=StratifiedKFold(10, random_state=random_state, shuffle=True), scoring="accuracy")
rfecv.fit(X, y)

plt.figure(figsize=(24, 6))
plt.plot(range(1, len(rfecv.grid_scores_)+1), rfecv.grid_scores_)
plt.grid()
plt.xticks(range(1, X.shape[1]+1))
plt.xlabel("Number of Selected Features")
plt.ylabel("CV Score")
plt.title("Recursive Feature Elimination (RFE)")
plt.show()

print("The optimal number of features: {}".format(rfecv.n_features_))

X_rfe = X.iloc[:, rfecv.support_]

print("\"X\" dimension: {}".format(X.shape))
print("\"X\" column list:", X.columns.tolist())
print("\"X_rfe\" dimension: {}".format(X_rfe.shape))
print("\"X_rfe\" column list:", X_rfe.columns.tolist())

"""Build Some ML Models"""

X_train, X_test, X_rfe_train, X_rfe_test, y_train, y_test = train_test_split(X, X_rfe, y, 
                                                                             train_size=0.8, 
                                                                             stratify=y,
                                                                             random_state=random_state)
print("Train size: {}".format(len(y_train)))
print("Test size: {}".format(len(y_test)))

clf_keys = ["Multi-layer Perceptron", "Logistic Regression"]
clf_values = [MLPClassifier(random_state=random_state, max_iter=1000), LogisticRegression(random_state=random_state)]
clf_rfe_keys = ["Multi-layer Perceptron", "Logistic Regression"]
clf_rfe_values = [MLPClassifier(random_state=random_state, max_iter=1000), LogisticRegression(random_state=random_state)]
clfs = dict(zip(clf_keys, clf_values))
clfs_rfe = dict(zip(clf_rfe_keys, clf_rfe_values))

# Original dataset
print("Model training using original data: started!")
for clf_name, clf in clfs.items():
    clf.fit(X_train, y_train)
    clfs[clf_name] = clf
    print(clf_name, "training: done!")
print("Model training using original data: done!\n")

# Feature-selected dataset
print("Model training using feature-selected data: started!")
for clf_rfe_name, clf_rfe in clfs_rfe.items():
    clf_rfe.fit(X_rfe_train, y_train)
    clfs_rfe[clf_rfe_name] = clf_rfe
    print(clf_rfe_name, "training: done!")
print("Model training using feature-selected data: done!")

"""Periksa keakuratan kedua model ini, untuk saat ini"""

# Original dataset
acc = []
for clf_name, clf in clfs.items():
    y_pred = clf.predict(X_test)
    acc.append(accuracy_score(y_test, y_pred))

# Feature selected dataset
acc_rfe = []
for clf_rfe_name, clf_rfe in clfs_rfe.items():
    y_rfe_pred = clf_rfe.predict(X_rfe_test)
    acc_rfe.append(accuracy_score(y_test, y_rfe_pred))
    
acc_all = pd.DataFrame({"Original dataset": acc, "Feature-selected dataset": acc_rfe},
                       index=clf_keys)
acc_all

"""Buat plot batang dari semua hasil akurasi untuk memvisualisasikannya."""

print("Accuracy\n" + acc_all.mean().to_string())

ax = acc_all.plot.bar(figsize=(10, 8))
for p in ax.patches:
    ax.annotate(str(p.get_height().round(3)), (p.get_x()*0.985, p.get_height()*1.002))
plt.ylim((0.7, 1.2))
plt.xticks(rotation=90)
plt.title("All Classifier Accuracies")
plt.grid()
plt.show()

"""Model Evaluation

Untuk memvalidasi hasil akurasi dan mengevaluasi kinerja kedua model ini lebih jauh, lakukan kipatgasi-validasi silang dengan k = 10k = 10 pada seluruh dataset. Metrik untuk memvalidasi adalah: akurasi, dan skor ROC AUC.
"""

scoring = ["accuracy", "roc_auc"]

scores = []
# Original dataset
print("Cross-validation on original data: started!")
for clf_name, clf in clfs.items():
    score = pd.DataFrame(cross_validate(clf, X, y, cv=StratifiedKFold(10, random_state=random_state, shuffle=True), scoring=scoring)).mean()
    scores.append(score)
    print(clf_name, "cross-validation: done!")
cv_scores = pd.concat(scores, axis=1).rename(columns=dict(zip(range(len(clf_keys)), clf_keys)))
print("Cross-validation on original data: done!\n")

scores = []
# Feature-selected dataset
print("Cross-validation on feature-selected data: started!")
for clf_name, clf in clfs_rfe.items():
    score = pd.DataFrame(cross_validate(clf, X_rfe, y, cv=StratifiedKFold(10, random_state=random_state, shuffle=True), scoring=scoring)).mean()
    scores.append(score)
    print(clf_name, "cross-validation: done!")
cv_scores_rfe = pd.concat(scores, axis=1).rename(columns=dict(zip(range(len(clf_keys)), clf_keys)))
print("Cross-validation on feature-selected data: done!")

# Accuracy
cv_acc_all = pd.concat([cv_scores.loc["test_accuracy"].rename("Original data"), cv_scores_rfe.loc["test_accuracy"].rename("Feature-selected data")], 
                       axis=1)

print("Cross-validation accuracy\n" + cv_acc_all.mean().to_string())
ax = cv_acc_all.plot.bar(figsize=(10, 8))
for p in ax.patches:
    ax.annotate(str(p.get_height().round(3)), (p.get_x()*0.985, p.get_height()*1.003))
plt.xticks(rotation=90)
plt.ylim((0.7, 1.2))
plt.title("Cross-validation Accuracy")
plt.grid()
plt.legend()
plt.show()

# ROC AUC
cv_roc_auc_all = pd.concat([cv_scores.loc["test_roc_auc"].rename("Original data"), cv_scores_rfe.loc["test_roc_auc"].rename("Feature-selected data")], 
                           axis=1)

print("Cross-validation ROC AUC score\n" + cv_roc_auc_all.mean().to_string())
ax = cv_roc_auc_all.plot.bar(figsize=(10, 8))
for p in ax.patches:
    ax.annotate(str(p.get_height().round(3)), (p.get_x()*0.985, p.get_height()*1.003))
plt.xticks(rotation=90)
plt.ylim((0.63, 1.2))
plt.title("Cross-validation ROC AUC Score")
plt.grid()
plt.legend()
plt.show()

# Fit time
cv_fit_time_all = pd.concat([cv_scores.loc["fit_time"].rename("Original data"), cv_scores_rfe.loc["fit_time"].rename("Feature-selected data")], 
                           axis=1)

print("Cross-validation fit time\n" + cv_fit_time_all.mean().to_string())
ax = cv_fit_time_all.plot.bar(figsize=(10, 8))
for p in ax.patches:
    ax.annotate(str(p.get_height().round(3)), (p.get_x()*0.985, p.get_height()*1.003))
plt.xticks(rotation=90)
plt.yscale("log")
plt.title("Cross-validation Fit Time")
plt.grid()
plt.legend()
plt.show()

"""LR"""

importance = abs(clfs["Logistic Regression"].coef_[0])
fig = plt.figure(figsize=(24, 30))
ax = fig.add_subplot()
ax.barh(X.columns.values[importance.argsort()], importance[importance.argsort()])
plt.title("Logistic Regression - Feature Importance (Original Data)")
ax.grid(True)
plt.show()

"""Feature Importance MultiLayer Perceptron"""

importance = abs(clfs["Multi-layer Perceptron"].coefs_[0])
len(importance)
fig = plt.figure(figsize=(24, 30))
plt.barh(X.columns.values[87], importance[0])
X_impt = [X.columns.values[87]]
for ab in range(87):
  plt.barh(X.columns.values[ab], importance[ab])

plt.title("Multilayer Perceptron - Feature Importance (Original Data)")
plt.grid()
plt.show()


importance_rfe = abs(clfs_rfe["Multi-layer Perceptron"].coefs_[0])
len(importance_rfe)
fig = plt.figure(figsize=(14, 8))
plt.barh(X_rfe.columns.values[46], importance_rfe[0])


X_rfe2 = [X_rfe.columns.values[46]]
for x in range(46):
  plt.barh(X_rfe.columns.values[x], importance_rfe[x])
  
plt.title("Multilayer Perceptron - Feature Importance (Feature-selected Data)")
plt.grid()
plt.show()

"""ranking RFE and MLP"""

importance_rfe = abs(clfs_rfe["Multi-layer Perceptron"].coefs_[0])
len(importance_rfe)
fig = plt.figure(figsize=(14, 8))
plt.barh(X_rfe.columns.values[46], importance_rfe[0])


X_rfe2 = [X_rfe.columns.values[46]]
for x in range(46):
  plt.barh(X_rfe.columns.values[x], importance_rfe[x])
  
plt.title("Multilayer Perceptron - Feature Importance (Feature-selected Data)")
plt.grid()
plt.show()

X

